base_model:
  - "Llama-2-7b-chat-hf"
dataset_size:
  - 300
#  - 900
#  - 1800
#  - 5000 # TODO: due to balancing, max. datasize currently is 17383 samples. There is more data in testing, but that would require further management to differenciate data.
#  - 10000
#  - 15000
num_epochs:
  - 3
#  - 4
#  - 5
lr:
#  - 1-3e
  - 1-4e
#  - 1-5e
temperature:
  - 0.1
#  - 0.3
#  - 0.5
#  - 0.8
#  - 1
top_k:
  - 1 # Greedy strategy
#  - 10
#  - 20
#  - 30
#  - 40
#  - 50
top_p:
#  - 0.15
#  - 0.25
#  - 0.5
#  - 0.75
  - 0.9
#  - 0.95
#  - 1.0 # 1.0 is kind-of deactivating top_p
